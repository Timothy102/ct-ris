{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "choice-process",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pc/.local/lib/python3.8/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 32) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 128, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 32) 9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128, 128, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 32) 128         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 128, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 16) 528         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 16)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 64)   9280        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 64, 64)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 64)   256         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 32)   2080        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 128)  36992       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 128)  147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 128)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 128)  512         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 64)   8256        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 256)  147712      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 256)  590080      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 16, 256)  0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 256)  1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 128)  32896       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 8, 8, 128)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 128)    512         average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 2048)   264192      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 2048)   8192        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 2048)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 512)    9437696     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 8, 8, 512)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 640)    0           average_pooling2d[0][0]          \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 640)    2560        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 640)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 320)    205120      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 4, 4, 320)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 320)    1280        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 4, 320)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 2048)   657408      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 4, 2048)   8192        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 4, 2048)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 512)    9437696     activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 4, 4, 512)    0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 4, 832)    0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 256)    1917184     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4, 4, 1088)   0           concatenate_1[0][0]              \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 1088)   4352        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 4, 1088)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 4, 4, 1024)   1115136     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 4, 1024)   4096        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 4, 4, 256)    2359552     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 4, 4, 256)    0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4, 4, 1344)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 8, 8, 1344)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 256)    344320      up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 256)    164096      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 256)    1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 256)    1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 8, 8, 256)    0           batch_normalization_19[0][0]     \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 256)    0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 128)    32896       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 128)    512         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 1)      129         batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 1)      4           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 8, 8, 640)    0           concatenate[0][0]                \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 8, 1984)   0           up_sampling2d[0][0]              \n",
      "                                                                 multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 1984)   7936        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 1984)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 2048)   4065280     activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 2048)   8192        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 2048)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 512)    9437696     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 8, 8, 512)    0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8, 8, 2496)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 2496) 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 128)  319616      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 128)  32896       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 128)  512         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 128)  512         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 16, 128)  0           batch_normalization_25[0][0]     \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 64)   8256        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 1)    65          batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 1)    4           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 16, 16, 256)  0           dropout_3[0][0]                  \n",
      "                                                                 batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 16, 16, 2752) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 256)  6340864     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 256)  1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 256)  1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 256)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16, 16, 256)  0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 64)   16448       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 64)   8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 64)   256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 64)   256         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           batch_normalization_31[0][0]     \n",
      "                                                                 batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 32)   2080        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 32)   128         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 32, 32, 1)    33          batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 32, 32, 1)    4           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 32, 32, 128)  0           dropout_2[0][0]                  \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 128)  442496      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 32, 32, 128)  512         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 128)  147584      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 32, 128)  512         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 128)  0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 64, 64, 32)   4128        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 64, 64, 32)   2080        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 64, 64, 32)   128         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 64, 64, 32)   128         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 32)   0           batch_normalization_37[0][0]     \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 64, 64, 32)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 64, 64, 16)   528         activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 64, 64, 16)   64          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 64, 64, 1)    17          batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 64, 64, 1)    4           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 64, 64, 64)   0           dropout_1[0][0]                  \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 64, 64, 192)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 64, 64, 64)   110656      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 64, 64, 64)   256         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 64, 64, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 64, 64, 64)   36928       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 64, 64, 64)   256         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 64, 64, 64)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 64, 64, 64)   0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 64) 0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 128, 128, 16) 1040        up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 128, 128, 16) 528         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 128, 128, 16) 64          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 128, 128, 16) 64          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 128, 16) 0           batch_normalization_43[0][0]     \n",
      "                                                                 batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 128, 128, 16) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 128, 128, 8)  136         activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 128, 128, 8)  32          conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 128, 128, 1)  9           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 128, 128, 1)  4           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 128, 128, 32) 0           dropout[0][0]                    \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 128, 128, 96) 0           up_sampling2d_4[0][0]            \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 128, 128, 32) 27680       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 128, 128, 32) 128         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 128, 128, 32) 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 128, 128, 32) 9248        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 128, 128, 32) 128         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 128, 128, 32) 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128, 128, 32) 0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 128, 128, 1)  33          dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 52,162,362\n",
      "Trainable params: 52,132,416\n",
      "Non-trainable params: 29,946\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as KTF\n",
    "\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, Activation, LeakyReLU, AveragePooling2D, Conv2D,ZeroPadding2D,Convolution2D, Conv2DTranspose,MaxPooling2D,add, UpSampling2D, multiply,Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,CSVLogger\n",
    "from tensorflow.keras import backend as K,models\n",
    "from skimage.io import imsave\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def merge(inputs, mode, concat_axis=-1):\n",
    "    return concatenate(inputs, concat_axis)\n",
    "\n",
    "#%%\n",
    "K.set_image_data_format('channels_last')  # TF dimension ordering in this code 此代码用于TF维度排序\n",
    "smooth = 1.\n",
    "\n",
    "img_rows =128\n",
    "img_cols =128\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "data_path = 'D:/18zhuhaipeng/ADIDC-Net/Covid/9229samples/change_original_result4_bz=32_dp=0.2_2dense_again/raw/file/'\n",
    "\n",
    "#加载训练数据\n",
    "def load_train_data():\n",
    "    imgs_train = np.load(data_path + 'train.npy')\n",
    "    imgs_mask_train = np.load(data_path + 'train_mask.npy')\n",
    "    return imgs_train, imgs_mask_train\n",
    "\n",
    "#加载验证数据\n",
    "def load_validation_data():\n",
    "    imgs_valid = np.load(data_path + 'validation.npy')\n",
    "    imgs_mask_valid = np.load(data_path + 'validation_mask.npy')\n",
    "    return imgs_valid, imgs_mask_valid\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.0-dice_coef(y_true, y_pred)\n",
    "\n",
    "#%%\n",
    "#计算灵敏度  \n",
    "def sensitivity(y_true,y_pred):\n",
    "    true_positives=tf.reduce_sum(tf.round(K.clip(y_true*y_pred, 0, 1)))\n",
    "    possible_positives=tf.reduce_sum(tf.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives+K.epsilon())\n",
    "#计算特异性\n",
    "def specificity(y_true,y_pred):\n",
    "    true_negatives=tf.reduce_sum(K.round(K.clip((1-y_true)*(1-y_pred), 0, 1)))\n",
    "    possible_negatives=tf.reduce_sum(K.round(K.clip((1-y_true), 0, 1)))\n",
    "    return true_negatives / (possible_negatives+K.epsilon())\n",
    "\n",
    "#%%\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.只计算批处理的平均精度。\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    计算精度，一个多标签分类的度量有多少选定的项目是相关的。\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "#%%\n",
    "def f1score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.仅计算批量平均召回率。\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        计算召回率，一个用于多标签分类的度量有多少相关的项目被选择。\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.只计算批处理的平均精度。\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        计算精度，一个多标签分类的度量有多少选定的项目是相关的。\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    " \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))      \n",
    "\n",
    "#%%\n",
    "def unet4(upsamezhi,chuandi,F_g, F_l,F_int):\n",
    "    up = Conv2D(F_g, (1, 1), activation='relu', padding='same')(upsamezhi)\n",
    "    up= BatchNormalization()(up)\n",
    "\n",
    "    down= Conv2D(F_l, (1, 1), activation='relu', padding='same')(chuandi)\n",
    "    down= BatchNormalization()(down)\n",
    "    \n",
    "    sumadd=add([up,down])\n",
    "    sumadd = Activation(activation='relu')(sumadd)\n",
    "    \n",
    "    \n",
    "    \n",
    "    jihe=Conv2D(F_int, (1, 1), activation='relu', padding='same')(sumadd)\n",
    "    sumhalf= BatchNormalization()(jihe)\n",
    "    \n",
    "    \n",
    "    sum_1=Conv2D(1, (1, 1), activation='sigmoid', padding='same')(sumhalf)\n",
    "    sum_1= BatchNormalization()(sum_1)\n",
    "    \n",
    "    xinchuandi=multiply([chuandi,sum_1])\n",
    "    return xinchuandi\n",
    "\n",
    "#%%\n",
    "def bottleneck(x, filters_bottleneck, mode='cascade', nb_layers=1,\n",
    "               kernel_size=(3, 3), activation='relu'):# used in the competition\n",
    "    if mode == 'cascade':\n",
    "        for i in range(nb_layers):\n",
    "            x1 = Conv2D(filters_bottleneck, kernel_size,activation=activation, \n",
    "               padding='same', dilation_rate=1)(x)\n",
    "            \n",
    "            x1 = Conv2D(filters_bottleneck, kernel_size,activation=activation,\n",
    "               padding='same', dilation_rate=2)(x1)\n",
    "            \n",
    "            x1 = Conv2D(filters_bottleneck, kernel_size,activation=activation,  \n",
    "               padding='same', dilation_rate=4)(x1)\n",
    "            \n",
    "            x1 = Conv2D(filters_bottleneck, kernel_size,activation=activation,  \n",
    "               padding='same', dilation_rate=8)(x1)\n",
    "            \n",
    "            x1 = Conv2D(filters_bottleneck, kernel_size,activation=activation,  \n",
    "               padding='same', dilation_rate=16)(x1)\n",
    "            \n",
    "            x1 = Conv2D(filters_bottleneck, kernel_size,activation=activation,  \n",
    "               padding='same', dilation_rate=1)(x1)\n",
    "            \n",
    "            x1 = Conv2D(filters_bottleneck, kernel_size,activation=activation,  \n",
    "               padding='same', dilation_rate=1)(x1)\n",
    "            \n",
    "            x = concatenate([x, x1], axis=3)\n",
    "        return x\n",
    "#%%\n",
    "def conv_block(x, nb_filter, alpha=0.0, drop_rate=0.2):\n",
    "    \n",
    "    x = Conv2D(nb_filter, kernel_size=(3, 3), padding='same', strides=(1, 1))(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    x = Conv2D(nb_filter, kernel_size=(3, 3), padding='same', strides=(1, 1))(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    if drop_rate: x = Dropout(drop_rate)(x)\n",
    "    return x\n",
    "#%%\n",
    "def bottleneck_layer(x, nb_filter, nb_size = 4, alpha=0.0, drop_rate=0.2): #nb_size = 4,\n",
    "    \n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    x = Conv2D(nb_size*nb_filter, kernel_size=(1, 1), padding='same', strides=(1, 1))(x)   #nb_size*\n",
    "    \n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    x = Conv2D(nb_filter, kernel_size=(3, 3), padding='same', strides=(1, 1))(x)\n",
    "    \n",
    "    if drop_rate: x = Dropout(drop_rate)(x)\n",
    "    \n",
    "    return x\n",
    "#%%\n",
    "def Dense_Block(x, growth_rate, nb_layers=1, drop_rate=0.2):  #Dense_Block(x, nb_layers, growth_rate, drop_rate=0.2)\n",
    "    \n",
    "    for i in range(nb_layers):\n",
    "        conv = bottleneck_layer(x, nb_filter=growth_rate, drop_rate=drop_rate)\n",
    "        x = concatenate([x, conv], axis=3)\n",
    "        return x\n",
    "\n",
    "#%%\n",
    "def TransitionLayer(x, compression=0.5, alpha=0.0, is_max=0):\n",
    "    \n",
    "    nb_filter = int(x.shape.as_list()[-1]*compression)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    x = Conv2D(nb_filter, (1, 1), strides=(1,1), padding='same')(x)\n",
    "    if is_max != 0: x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "    else: x = AveragePooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "    \n",
    "    return x\n",
    "     \n",
    "#%%\n",
    "def encoder(x):\n",
    "    to_decoder = []\n",
    "    #128*128*32    first branching to decoder\n",
    "    main_path = conv_block(x, 32, drop_rate=0.2)\n",
    "    to_decoder.append(main_path)\n",
    "    \n",
    "    #64*64*64      second branching to decoder\n",
    "    main_path = TransitionLayer(main_path, is_max =1)\n",
    "    main_path = conv_block(main_path, 64, drop_rate=0.2)\n",
    "    to_decoder.append(main_path)\n",
    "    \n",
    "    #32*32*128     third branching to decoder\n",
    "    main_path = TransitionLayer(main_path, is_max =1)\n",
    "    main_path = conv_block(main_path, 128, drop_rate=0.2)\n",
    "    to_decoder.append(main_path)\n",
    "    \n",
    "    #16*16*256     fourth branching to decoder\n",
    "    main_path = TransitionLayer(main_path, is_max =1)\n",
    "    main_path = conv_block(main_path, 256, drop_rate=0.2)\n",
    "    to_decoder.append(main_path)\n",
    "    \n",
    "    #8*8*512\n",
    "    main_path = TransitionLayer(main_path, is_max=0)\n",
    "    main_path = Dense_Block(main_path, 512, drop_rate=0.2)\n",
    "    to_decoder.append(main_path)\n",
    "    return to_decoder\n",
    "\n",
    "\n",
    "def decoder(x, from_encoder):#\n",
    "    #8*8*256\n",
    "    main_path = UpSampling2D(size=(2, 2))(x)  \n",
    "    xin_encoder_1 = unet4(main_path,from_encoder[4],256, 256,128)#\n",
    "    main_path = concatenate([main_path, xin_encoder_1], axis=3)\n",
    "    main_path = Dense_Block(main_path, 512, drop_rate=0.2)\n",
    "    # \n",
    "    #16*16*128\n",
    "    main_path = UpSampling2D(size=(2, 2))(main_path)\n",
    "    xin_encoder_2 = unet4(main_path,from_encoder[3],128, 128,64)\n",
    "    main_path = concatenate([main_path, xin_encoder_2], axis=3)\n",
    "    main_path = conv_block(main_path, 256, drop_rate=0.2)\n",
    "    \n",
    "    #32*32*64\n",
    "    main_path = UpSampling2D(size=(2, 2))(main_path)\n",
    "    xin_encoder_3 = unet4(main_path,from_encoder[2],64, 64,32)\n",
    "    main_path = concatenate([main_path, xin_encoder_3], axis=3)\n",
    "    main_path = conv_block(main_path, 128, drop_rate=0.2)\n",
    "    \n",
    "    #64*64*32\n",
    "    main_path = UpSampling2D(size=(2, 2))(main_path)\n",
    "    xin_encoder_4 = unet4(main_path,from_encoder[1],32, 32,16)\n",
    "    main_path = concatenate([main_path, xin_encoder_4], axis=3)\n",
    "    main_path = conv_block(main_path, 64, drop_rate=0.2)\n",
    "    \n",
    "    #128*128*16\n",
    "    main_path = UpSampling2D(size=(2, 2))(main_path)\n",
    "    xin_encoder_5 = unet4(main_path,from_encoder[0],16, 16,8)\n",
    "    main_path = concatenate([main_path, xin_encoder_5], axis=3)\n",
    "    main_path = conv_block(main_path, 32, drop_rate=0.2)\n",
    "    \n",
    "    return main_path\n",
    "\n",
    "\n",
    "def build_res_unet( ):\n",
    "    #inputs = Input(shape=input_shape)\n",
    "    inputs = Input(shape=(img_rows, img_cols, 1)) #128*128*1\n",
    "\n",
    "    to_decoder = encoder(inputs)\n",
    "    \n",
    "    path = TransitionLayer(to_decoder[4], is_max=0)\n",
    "    path = Dense_Block(path, 512, drop_rate=0.2) #4*4*512\n",
    "    \n",
    "    bottle = bottleneck(path, filters_bottleneck=256, mode='cascade')#4*4*256\n",
    "    \n",
    "    path1 = Dense_Block(bottle, 256, drop_rate=0.2) #4*4*256\n",
    "    \n",
    "    path = decoder(path1, from_encoder=to_decoder)\n",
    "\n",
    "    path = Conv2D(filters=1, kernel_size=(1, 1), activation='hard_sigmoid',padding='same')(path)#activation='hard_sigmoid'可改为activation='softmax'\n",
    "    \n",
    "    model=Model(inputs=inputs, outputs=path)\n",
    "    \n",
    "\n",
    "             \n",
    "    model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef, sensitivity,specificity,f1score,precision])\n",
    "\n",
    "    return model\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i], (img_cols, img_rows), preserve_range=True)\n",
    "\n",
    "    imgs_p = imgs_p[..., np.newaxis]\n",
    "    return imgs_p\n",
    "\n",
    "\n",
    "def train():\n",
    "    print('-' * 30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-' * 30)\n",
    "    imgs_train, imgs_mask_train = load_train_data()\n",
    "    imgs_valid, imgs_mask_valid = load_validation_data()\n",
    "\n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    print(imgs_train.shape)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    "    print(imgs_mask_train.shape)\n",
    "    imgs_valid = preprocess(imgs_valid)\n",
    "    print(imgs_valid.shape)\n",
    "    imgs_mask_valid = preprocess(imgs_mask_valid)\n",
    "    print(imgs_mask_valid.shape)\n",
    "\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    imgs_valid = imgs_valid.astype('float32')\n",
    "\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    val_mean = np.mean(imgs_valid)\n",
    "    val_std = np.std(imgs_valid)\n",
    "\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_valid -= val_mean\n",
    "    imgs_valid /= val_std\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
    "\n",
    "    imgs_mask_valid = imgs_mask_valid.astype('float32')\n",
    "    imgs_mask_valid /= 255.\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-' * 30)\n",
    "    model =build_res_unet()\n",
    "    model_checkpoint = ModelCheckpoint('D:/18zhuhaipeng/ADIDC-Net/Covid/9229samples/change_original_result4_bz=32_dp=0.2_2dense_again/raw/file/ADIDC-Net-again.hdf5',\n",
    "                                       monitor='val_loss',\n",
    "                                       save_best_only=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Fitting model...')\n",
    "    print('-' * 30)\n",
    "    #earlystopper=EarlyStopping(monitor='val_loss',patience=10,verbose=1)\n",
    "    his = model.fit(imgs_train, imgs_mask_train, batch_size=32, epochs=300, verbose=1, shuffle=True,\n",
    "                    validation_data=(imgs_valid, imgs_mask_valid), callbacks=[model_checkpoint])\n",
    "  \n",
    "    \n",
    "    score_1=model.evaluate(imgs_train,imgs_mask_train,batch_size=32,verbose=1)\n",
    "    print(' Train loss:',score_1[0])\n",
    "    print(' Train accuracy:',score_1[1])\n",
    "    print(' Train dice_coef:',score_1[2])\n",
    "    print(' Train sensitivity:',score_1[3])\n",
    "    print(' Train specificity:',score_1[4])\n",
    "    print(' Train f1score:',score_1[5])\n",
    "    print('Train precision:',score_1[6])\n",
    "    res_loss_1 = np.array(score_1)\n",
    "    np.savetxt(data_path+ 'res_loss_1.txt', res_loss_1)\n",
    "    \n",
    "    score_2=model.evaluate(imgs_valid,imgs_mask_valid,batch_size=32, verbose=1)\n",
    "    print(' valid loss:',score_2[0])\n",
    "    print(' valid  accuracy:',score_2[1])\n",
    "    print(' valid  dice_coef:',score_2[2])\n",
    "    print(' valid  sensitivity:',score_2[3])\n",
    "    print(' valid  specificity:',score_2[4])\n",
    "    print(' valid f1score:',score_2[5])\n",
    "    print('valid  precision:',score_2[6])\n",
    "    res_loss_2 = np.array(score_2)\n",
    "    np.savetxt(data_path + 'res_loss_2.txt', res_loss_2)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    model = build_res_unet()\n",
    "    print(model.summary())\n",
    "    # train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "manufactured-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history, metric = 'loss'):\n",
    "    plt.plot(history.history[metric], label='train loss')\n",
    "    plt.plot(history.history['val_' + metric])\n",
    "    plt.title(metric)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
