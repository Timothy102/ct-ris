{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mexican-jumping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-kennedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Razpis.docx',\n",
       " 'Pravilnik.docx',\n",
       " 'cnn.ipynb',\n",
       " 'Ct.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'overview.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_DIR = os.getcwd()\n",
    "os.listdir(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-camera",
   "metadata": {},
   "source": [
    "## Plot to make sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glob_list(path = 'normal'):\n",
    "    imgs = []\n",
    "    for img_path in glob.glob(DATASET_DIR + '/' + path + '/*'):\n",
    "        imgs.append(mpimg.imread(img_path))\n",
    "    return imgs\n",
    "\n",
    "def plot(img):\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('normal')\n",
    "    plt.imshow(normal_images[0], cmap='gray') \n",
    "\n",
    "def grid(x,y):\n",
    "    f, axarr = plt.subplots(2,2)\n",
    "    axarr[0,0].imshow(x[0])\n",
    "    axarr[0,1].imshow(y[0])\n",
    "    axarr[1,0].imshow(x[1])\n",
    "    axarr[1,1].imshow(y[1])\n",
    "\n",
    "normal_images = glob_list('normal')\n",
    "covid_images = glob_list('covid')\n",
    "\n",
    "plot(normal_images[0])\n",
    "plot(covid_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid(normal_images,covid_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-huntington",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ethical-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_W = 150\n",
    "IMG_H = 150\n",
    "CHANNELS = 3\n",
    "\n",
    "INPUT_SHAPE = (IMG_W, IMG_H, CHANNELS)\n",
    "N_CLASSES = 2\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 12\n",
    "\n",
    "log_dir = '/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(validation_split = 0.3)\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    DATASET_DIR,\n",
    "    target_size=(IMG_H, IMG_W),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training')\n",
    "\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    DATASET_DIR, \n",
    "    target_size=(IMG_H, IMG_W),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle= False,\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-compatibility",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "scenic-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Activation, Flatten, BatchNormalization,AvgPool2D,MaxPool2D, Dropout,Conv2DTranspose, Reshape, Lambda, LeakyReLU, UpSampling2D, concatenate\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint,TensorBoard\n",
    "\n",
    "es = EarlyStopping(monitor = 'loss', mode = 'auto')\n",
    "rl = ReduceLROnPlateau(monitor = 'val_accuracy', patience = 2)\n",
    "check = ModelCheckpoint(filepath = '/checkpoints',monitor = 'accuracy', save_weights_only = False, save_freq='epoch')\n",
    "tensorboard = TensorBoard(log_dir = log_dir, histogram_freq=10, write_graph=True, write_images=False)\n",
    "\n",
    "cbs = [es, rl, check, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "chronic-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_build(model, input_shape = INPUT_SHAPE):\n",
    "    model.build(INPUT_SHAPE)\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-mission",
   "metadata": {},
   "source": [
    "### Convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "acceptable-links",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_251 (Conv2D)          (None, 148, 148, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_104 (MaxPoolin (None, 74, 74, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_252 (Conv2D)          (None, 72, 72, 16)        9232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_105 (MaxPoolin (None, 36, 36, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 32)                663584    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 674,641\n",
      "Trainable params: 674,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "act = tf.nn.leaky_relu\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3,3), input_shape = INPUT_SHAPE, activation=act),\n",
    "    MaxPooling2D((2,2)),\n",
    "    #Conv2D(32, (3,3), activation = act),\n",
    "    #MaxPooling2D((2,2)),\n",
    "    Conv2D(16,(3,3), activation = act),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(32, activation = act),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "compile_and_build(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-module",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "def AlexNet(input_shape):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = Conv2D(96,(11,11),strides = 4,name=\"conv0\")(X_input)\n",
    "    X = BatchNormalization(axis = 3 , name = \"bn0\")(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = MaxPooling2D((3,3),strides = 2,name = 'max0')(X)\n",
    "    \n",
    "    X = Conv2D(256,(5,5),padding = 'same' , name = 'conv1')(X)\n",
    "    X = BatchNormalization(axis = 3 ,name='bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = MaxPooling2D((3,3),strides = 2,name = 'max1')(X)\n",
    "    \n",
    "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv2')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(384, (3,3) , padding = 'same' , name='conv3')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(256, (3,3) , padding = 'same' , name='conv4')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn4')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = MaxPooling2D((3,3),strides = 2,name = 'max2')(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    X = Dense(4096, activation = 'relu', name = \"fc0\")(X)\n",
    "    \n",
    "    X = Dense(4096, activation = 'relu', name = 'fc1')(X) \n",
    "    \n",
    "    X = Dense(len(dummy_labels),activation='softmax',name = 'fc2')(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='AlexNet')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-plymouth",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "verbal-account",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_255 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_108 (MaxPoolin (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_256 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_109 (MaxPoolin (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "latent (Dense)               (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 3136)              404544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_13 (Reshape)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_59 (Conv2DT (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_60 (Conv2DT (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 28, 28, 1)         4         \n",
      "_________________________________________________________________\n",
      "outputs (Activation)         (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 863,045\n",
      "Trainable params: 862,723\n",
      "Non-trainable params: 322\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "H = 28\n",
    "W = 28\n",
    "C = 1\n",
    "\n",
    "## Latent space\n",
    "latent_dim = 128\n",
    "\n",
    "## Building the autoencoder\n",
    "inputs = Input(shape=(H, W, C), name=\"inputs\")\n",
    "x = inputs\n",
    "\n",
    "x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "x = MaxPool2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "x = MaxPool2D((2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "units = x.shape[1]\n",
    "x = Dense(latent_dim, name=\"latent\")(x)\n",
    "x = Dense(units)(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "x = Reshape((7, 7, 64))(x)\n",
    "\n",
    "x = Conv2DTranspose(64, (3, 3), strides=2, padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = Conv2DTranspose(1, (3, 3), strides=2, padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"sigmoid\", name=\"outputs\")(x)\n",
    "\n",
    "outputs = x\n",
    "\n",
    "autoencoder = Model(inputs, outputs)\n",
    "autoencoder.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "similar-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoenc_plot():\n",
    "    n = 10\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "      # display original\n",
    "      ax = plt.subplot(2, n, i + 1)\n",
    "      plt.imshow(x_test[i])\n",
    "      plt.title(\"original\")\n",
    "      plt.gray()\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)\n",
    "\n",
    "      # display reconstruction\n",
    "      ax = plt.subplot(2, n, i + 1 + n)\n",
    "      plt.imshow(decoded_imgs[i])\n",
    "      plt.title(\"reconstructed\")\n",
    "      plt.gray()\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-ladder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "statistical-naples",
   "metadata": {},
   "source": [
    "### UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "attractive-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "opening-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "waiting-entity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 128, 128, 16) 160         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 128, 128, 16) 64          conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 128, 128, 16) 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling2D) (None, 64, 64, 16)   0           activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 64, 64, 16)   0           max_pooling2d_79[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 64, 64, 32)   4640        dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 64, 64, 32)   128         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 64, 64, 32)   0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling2D) (None, 32, 32, 32)   0           activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 32, 32, 32)   0           max_pooling2d_80[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 32, 32, 64)   18496       dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 32, 32, 64)   256         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 32, 32, 64)   0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling2D) (None, 16, 16, 64)   0           activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 16, 16, 64)   0           max_pooling2d_81[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 16, 16, 128)  73856       dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 16, 16, 128)  512         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 16, 16, 128)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling2D) (None, 8, 8, 128)    0           activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 8, 8, 128)    0           max_pooling2d_82[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 8, 8, 256)    295168      dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 8, 8, 256)    1024        conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 256)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_53 (Conv2DTran (None, 16, 16, 128)  295040      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 256)  0           conv2d_transpose_53[0][0]        \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 16, 16, 256)  0           concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 16, 16, 128)  295040      dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 16, 16, 128)  512         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 16, 16, 128)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_54 (Conv2DTran (None, 32, 32, 64)   73792       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 32, 32, 128)  0           conv2d_transpose_54[0][0]        \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 32, 32, 128)  0           concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 32, 32, 64)   73792       dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 32, 32, 64)   256         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 32, 32, 64)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_55 (Conv2DTran (None, 64, 64, 32)   18464       activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 64, 64, 64)   0           conv2d_transpose_55[0][0]        \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 64, 64, 64)   0           concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 64, 64, 32)   18464       dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 64, 64, 32)   128         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 64, 64, 32)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_56 (Conv2DTran (None, 128, 128, 16) 4624        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 128, 128, 32) 0           conv2d_transpose_56[0][0]        \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 128, 128, 32) 0           concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 128, 128, 16) 4624        dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 128, 128, 16) 64          conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 128, 128, 16) 0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 128, 128, 1)  17          activation_101[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,179,121\n",
      "Trainable params: 1,177,649\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input((128, 128,1), name='img')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model.compile(optimizer='rmsprop', loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-hammer",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model = model, restore=False, filename=model_dir, args=args):\n",
    "    if restore: \n",
    "        model = load_model(filename)\n",
    "    history = model.fit(train_generator, validation_data = val_generator,epochs=args.epochs,callbacks=callbacks,batch_size=args.batch_size, verbose=3)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # ACCURACY\n",
    "    plt.plot(acc)\n",
    "    plt.plot(val_acc)\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    # LOSS\n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-centre",
   "metadata": {},
   "source": [
    "## Hp tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls logs/hparam_tuning\n",
    "!rm -rf ./logs/\n",
    "!rm -rf checkpoint\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([8, 64]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.3))\n",
    "HP_LEARNING_RATE= hp.HParam('learning_rate', hp.Discrete([0.001, 0.0005, 0.0001]))\n",
    "HP_OPTIMIZER=hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', 'rmsprop']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "log_dir ='\\\\logs\\\\fit\\\\' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "with tf.summary.create_file_writer(log_dir).as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_DROPOUT,  HP_OPTIMIZER, HP_LEARNING_RATE],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hparams):\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(512,input_shape=[5]),\n",
    "        Dense(128,activation='relu',kernel_regularizer=l1(1e-4)),\n",
    "        BatchNormalization(),\n",
    "        Dense(128,activation='relu'),\n",
    "        Dropout(hparams[HP_DROPOUT]),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(hparams[HP_DROPOUT]),\n",
    "        Dense(hparams[HP_NUM_UNITS], activation='relu'),\n",
    "        Dense(16,activation='relu'),    \n",
    "        Dense(1)\n",
    "    ], name = 'rentals_model')\n",
    "    optimizer = hparams[HP_OPTIMIZER]\n",
    "    learning_rate = hparams[HP_LEARNING_RATE]\n",
    "    \n",
    "    if optimizer == \"adam\":\n",
    "        optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == \"sgd\":\n",
    "        optimizer = tf.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer=='rmsprop':\n",
    "        optimizer = tf.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"Not an optimizer name: %r\" % (optimizer_name,))\n",
    "    \n",
    "    model.compile(optimizer = optimizer, loss = Huber(), metrics=['RootMeanSquaredError'])\n",
    "    return model\n",
    "def train_and_evaluate(model, hparams):\n",
    "    \n",
    "    hp_tuning = hp.KerasCallback(log_dir, hparams),\n",
    "    cbs = [tensorboard, hp_tuning]\n",
    "    \n",
    "    history = model.fit(x_train, y_train,validation_split=0.1,epochs=100, shuffle = True, callbacks = cbs,verbose=2)\n",
    "    _, rmse = model.evaluate(x_test,y_test)\n",
    "    return rmse, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(hparams)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        model = create_model(hparams)\n",
    "        accuracy, history = train_and_evaluate(model, hparams)\n",
    "        #accuracy= tf.reshape(tf.convert_to_tensor(accuracy), []).numpy()\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "    return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
